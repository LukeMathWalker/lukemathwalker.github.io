	<!DOCTYPE html>
<html lang="en-uk">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		
		<meta name="author" content="Luca Palmieri">
		<meta name="description" content="A personal blog focused on AI content and tutorials.">
		<meta name="generator" content="Hugo 0.33" />
		<title>Travel journal of an AI adventure</title>
		<link rel="shortcut icon" href="http://lpalmieri.com/images/favicon.ico">
		<link rel="stylesheet" href="http://lpalmieri.com/css/style.css">
		<link rel="stylesheet" href="http://lpalmieri.com/css/highlight.css">

		
		<link rel="stylesheet" href="http://lpalmieri.com/css/font-awesome.min.css">
		

		
		<link href="http://lpalmieri.com/index.xml" rel="alternate" type="application/rss+xml" title="Travel journal of an AI adventure" />
		

		
	</head>

	<body>
    <nav class="main-nav">
	
	
	<a href='http://lpalmieri.com/posts'>Archive</a>
	<a href='http://lpalmieri.com/tags'>Tags</a>
	<a href='http://lpalmieri.com/about'>About</a>

	

	
	<a class="cta" href="http://lpalmieri.com/index.xml">Subscribe</a>
	
</nav>


    <div class="profile">
    <section id="wrapper">
        <header id="header">
            <a href='http://lpalmieri.com/about'>
                <img id="avatar" class="2x" src="http://lpalmieri.com/images/avatar.png"/>
            </a>
            <h1>Travel journal of an AI adventure</h1>
            <h2>Sparse entries from a discovery journey.</h2>
        </header>
    </section>
</div>


    <section id="wrapper" class="home">
        <ul id="post-list">
    
    
        
            <li>
                <aside class="dates">Dec 28</aside>
                <a href='http://lpalmieri.com/posts/my-first-post/'>
                    Reinforcement Learning: a comprehensive introduction [Part 1]
                    
                        
                            <h2>Policies Decision rules A randomized history-dependent decision rule $d_t$ is a mapping between the history of our system up to the current state $t$ and the probability of selecting each possible action. What is the history of the system? Nothing more than the sequence of past actions and states, assuming that past rewards do not influence our future behaviour. We shall denote the history of our system up to time $t$ as $$\begin{equation}h_t=(s_1, a_1, s_2, \dots, a_{t-1}, s_t) \quad\quad t\in\{1, 2, \dots\}\end{equation}$$ or, using a little bit of recursion, $$\begin{equation}\begin{split} h_t &amp;amp;= (h_{t-1}, a_{t-1}, s_t) \quad\quad\quad\quad t\in\{2, \dots\} \\ h_1 &amp;amp;= s_1 \end{split}\end{equation}$$ The set of histories can be defined as $$\begin{equation}\begin{split} \mathcal{H}_t &amp;amp;= \mathcal{S}\times \prod_2^t (\mathcal{A}\times \mathcal{S}) \quad\quad t\in\{2, \dots\} \\ \mathcal{H}_1 &amp;amp;= \mathcal{S} \end{split}\end{equation}$$ or, equivalenty, $$\begin{equation}\begin{split} \mathcal{H}_t &amp;amp;=\mathcal{H}_{t-1}\times \mathcal{A}\times \mathcal{S} \quad\quad t\in\{2, \dots\} \\ \mathcal{H}_1 &amp;amp;= \mathcal{S} \end{split}\end{equation}$$ We can thus formalize the concept of history-dependent decision rule as a function $$\begin{equation} d_t: \mathcal{H}_t \to \mathcal{P}(A) \end{equation}$$ where $\mathcal{P}(A)$ denotes the collection of probability distributions over the set of actions $\mathcal{A}$.</h2>
                        
                    
                </a>
            </li>
        
    
</ul>

        <nav id="post-nav">
    
</nav>
        <footer id="footer">
    
        <div id="social">

	
	
    <a class="symbol" href="https://www.github.com/LukeMathWalker">
        <i class="fa fa-github-square"></i>
    </a>
    
    <a class="symbol" href="https://www.linkedin.com/in/luca-palmieri/">
        <i class="fa fa-linkedin-square"></i>
    </a>
    


</div>

    
    <p class="small">
    
       Â© Copyright 2018 <i class="fa fa-heart" aria-hidden="true"></i> Luca Palmieri
    
    </p>
    <p class="small">
        Powered by <a href="http://www.gohugo.io/">Hugo</a> Theme By <a href="https://github.com/nodejh/hugo-theme-cactus-plus">nodejh</a>
    </p>
</footer>

    </section>

    <script src="http://lpalmieri.com/js/jquery-2.2.4.min.js"></script>
<script src="http://lpalmieri.com/js/main.js"></script>
<script src="http://lpalmieri.com/js/highlight.min.js"></script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "all" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({

  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

<script>hljs.initHighlightingOnLoad();</script>







    </body>
</html>
