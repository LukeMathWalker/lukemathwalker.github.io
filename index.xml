<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Travel journal of an AI adventure</title>
    <link>http://lukemathwalker.github.io/</link>
    <description>Recent content on Travel journal of an AI adventure</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-uk</language>
    <lastBuildDate>Thu, 28 Dec 2017 21:36:08 +0100</lastBuildDate>
    
	<atom:link href="http://lukemathwalker.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Reinforcement Learning: a comprehensive introduction [Part 1]</title>
      <link>http://lukemathwalker.github.io/posts/my-first-post/</link>
      <pubDate>Thu, 28 Dec 2017 21:36:08 +0100</pubDate>
      
      <guid>http://lukemathwalker.github.io/posts/my-first-post/</guid>
      <description>0$` such that `$|R_t|\leq M$` for all `$t$` - we still have that `$G_t$` is finite. In fact: `$$ |G_t| \leq \sum_{k=t+1}^{+\infty}\left|\gamma^{k-t-1}R_k\right| = \sum_{k=t+1}^{+\infty}\gamma^{k-t-1}\left|R_k\right| \leq M \sum_{k=t+1}^{+\infty}\gamma^{k-t-1} = \frac{M}{1-\gamma} Policies Decision rules A randomized history-dependent decision rule $d_t$ is a mapping between the history of our system up to the current state $t$ and the probability of selecting each possible action. What is the history of the system? Nothing more than the sequence of past actions and states, assuming that past rewards do not influence our future behaviour.</description>
    </item>
    
  </channel>
</rss>